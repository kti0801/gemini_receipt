{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ced5b89d11494a9bab1d52e519383d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51cb382d312c43efbdb5fd8e82b9bb6f",
              "IPY_MODEL_c8538de065954d0b82cfad9f37230520",
              "IPY_MODEL_448243646bea460c97899b8122c13ffa"
            ],
            "layout": "IPY_MODEL_39bba564e6924363afeeca001507da52"
          }
        },
        "51cb382d312c43efbdb5fd8e82b9bb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f622ec8283948b0907595c3190a5aaf",
            "placeholder": "​",
            "style": "IPY_MODEL_b4a1609adbe54fb58108ee452ec08147",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "c8538de065954d0b82cfad9f37230520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a102a1dfca7f42e7bbafac49b86cc283",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f462601332f4322bdf1d43a09b8fc6a",
            "value": 2
          }
        },
        "448243646bea460c97899b8122c13ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df27038c9fb345249fc4a32bd45180ef",
            "placeholder": "​",
            "style": "IPY_MODEL_aab57981c8d546828cb8bc5a7924469b",
            "value": " 2/2 [00:59&lt;00:00, 26.49s/it]"
          }
        },
        "39bba564e6924363afeeca001507da52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f622ec8283948b0907595c3190a5aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a1609adbe54fb58108ee452ec08147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a102a1dfca7f42e7bbafac49b86cc283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f462601332f4322bdf1d43a09b8fc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df27038c9fb345249fc4a32bd45180ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aab57981c8d546828cb8bc5a7924469b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab으로 오픈소스 LLM 구동하기"
      ],
      "metadata": {
        "id": "ybMCVFh0_5R8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1단계 - LLM 양자화에 필요한 패키지 설치\n",
        "- bitsandbytes: Bitsandbytes는 CUDA 사용자 정의 함수, 특히 8비트 최적화 프로그램, 행렬 곱셈(LLM.int8()) 및 양자화 함수에 대한 경량 래퍼\n",
        "- PEFT(Parameter-Efficient Fine-Tuning): 모델의 모든 매개변수를 미세 조정하지 않고도 사전 훈련된 PLM(언어 모델)을 다양한 다운스트림 애플리케이션에 효율적으로 적용 가능\n",
        "- accelerate: PyTorch 모델을 더 쉽게 여러 컴퓨터나 GPU에서 사용할 수 있게 해주는 도구\n"
      ],
      "metadata": {
        "id": "juj9DSmmh-Gw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nNWXXc7ol1n",
        "outputId": "e7bb7cfa-f28d-44e9-858b-dc3a8e10b999"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#양자화에 필요한 패키지 설치\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2단계 - 트랜스포머에서 BitsandBytesConfig를 통해 양자화 매개변수 정의하기\n",
        "\n",
        "\n",
        "* load_in_4bit=True: 모델을 4비트 정밀도로 변환하고 로드하도록 지정\n",
        "* bnb_4bit_use_double_quant=True: 메모리 효율을 높이기 위해 중첩 양자화를 사용하여 추론 및 학습\n",
        "* bnd_4bit_quant_type=\"nf4\": 4비트 통합에는 2가지 양자화 유형인 FP4와 NF4가 제공됨. NF4 dtype은 Normal Float 4를 나타내며 QLoRA 백서에 소개되어 있습니다. 기본적으로 FP4 양자화 사용\n",
        "* bnb_4bit_compute_dype=torch.bfloat16: 계산 중 사용할 dtype을 변경하는 데 사용되는 계산 dtype. 기본적으로 계산 dtype은 float32로 설정되어 있지만 계산 속도를 높이기 위해 bf16으로 설정 가능\n",
        "\n"
      ],
      "metadata": {
        "id": "3NVvNhohkvwF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "kvvLg99Opw5R"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3단계 - 경량화 모델 로드하기"
      ],
      "metadata": {
        "id": "xeQRE1sBmT87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 모델 ID를 지정한 다음 이전에 정의한 양자화 구성으로 로드합니다."
      ],
      "metadata": {
        "id": "NgqxSuxsBX3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"kyujinpy/Ko-PlatYi-6B\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "7St-hFLNmS2v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "ced5b89d11494a9bab1d52e519383d1d",
            "51cb382d312c43efbdb5fd8e82b9bb6f",
            "c8538de065954d0b82cfad9f37230520",
            "448243646bea460c97899b8122c13ffa",
            "39bba564e6924363afeeca001507da52",
            "2f622ec8283948b0907595c3190a5aaf",
            "b4a1609adbe54fb58108ee452ec08147",
            "a102a1dfca7f42e7bbafac49b86cc283",
            "4f462601332f4322bdf1d43a09b8fc6a",
            "df27038c9fb345249fc4a32bd45180ef",
            "aab57981c8d546828cb8bc5a7924469b"
          ]
        },
        "outputId": "d5f80da4-cc8c-41c0-d154-929b230c99ed"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ced5b89d11494a9bab1d52e519383d1d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "sEOaA_09yQIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e04b09e9-039e-426c-de6d-1285d92a17a1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LlamaForCausalLM(\n",
            "  (model): LlamaModel(\n",
            "    (embed_tokens): Embedding(78464, 4096, padding_idx=0)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x LlamaDecoderLayer(\n",
            "        (self_attn): LlamaSdpaAttention(\n",
            "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=4096, out_features=512, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=4096, out_features=512, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
            "          (rotary_emb): LlamaRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): LlamaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): LlamaRMSNorm()\n",
            "        (post_attention_layernorm): LlamaRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): LlamaRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=78464, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4단계 - 잘 실행되는지 확인"
      ],
      "metadata": {
        "id": "eyHol6vSi9JN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"뉴턴과 아인슈타인이 서로 팔씨름을 하면 누가 이길지 추론해줘\"}\n",
        "]\n",
        "\n",
        "\n",
        "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
        "\n",
        "model_inputs = encodeds.to(device)\n",
        "\n",
        "\n",
        "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
        "decoded = tokenizer.batch_decode(generated_ids)\n",
        "print(decoded[0])"
      ],
      "metadata": {
        "id": "TDkUkF2So2-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae29faa-506f-4098-87ba-0ff657968534"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|startoftext|> [INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
            "\n",
            "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "\n",
            "뉴턴과 아인슈타인이 서로 팔씨름을 하면 누가 이길지 추론해줘 [/INST]<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5단계- RAG 시스템 결합하기"
      ],
      "metadata": {
        "id": "nCFt0vCWbV-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install시 utf-8, ansi 관련 오류날 경우 필요한 코드\n",
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "Mb1yQDjf9O2m"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaleido python-multipart\n"
      ],
      "metadata": {
        "id": "1FKWkosOP7RW",
        "outputId": "d9f35a97-209a-4c0b-9434-fda23cf9e146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaleido in /usr/local/lib/python3.10/dist-packages (0.2.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (0.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing-extensions==4.5.0\n"
      ],
      "metadata": {
        "id": "PNwHBFNJQCqt",
        "outputId": "bc16bc38-1b47-4fa9-f9a1-7de2cb0d4321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting typing-extensions==4.5.0\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.30 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "fastapi 0.111.0 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic 2.7.3 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.18.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "torch 2.3.0+cu121 requires typing-extensions>=4.8.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain pypdf chromadb sentence-transformers faiss-gpu"
      ],
      "metadata": {
        "id": "UmvYgQ380O-N"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "id": "Glepcs7aS1QM",
        "outputId": "0f740b18-2f9b-41b0-866a-89d88d596b87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.5)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.9)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.80)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.5->langchain-community) (2.7.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.5->langchain-community) (2.18.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from transformers import pipeline\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "text_generation_pipeline = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=300,\n",
        ")\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "### [INST]\n",
        "Instruction: Answer the question based on your knowledge.\n",
        "Here is context to help:\n",
        "\n",
        "{context}\n",
        "\n",
        "### QUESTION:\n",
        "{question}\n",
        "\n",
        "[/INST]\n",
        " \"\"\"\n",
        "\n",
        "koplatyi_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n",
        "# Create prompt from prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=prompt_template,\n",
        ")\n",
        "\n",
        "# Create llm chain\n",
        "llm_chain = LLMChain(llm=koplatyi_llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "6acsSeMto3Ik"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.schema.runnable import RunnablePassthrough"
      ],
      "metadata": {
        "id": "0oAiR0fH6c0E"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgXthDeN9ky1",
        "outputId": "75a68944-6291-4698-b78d-c23ea8a195a2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/drive/MyDrive/Colab Notebooks/ESTsoft - The most universal interface for human.pdf\")\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "texts = text_splitter.split_documents(pages)\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "model_name = \"jhgan/ko-sbert-nli\"\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "db = FAISS.from_documents(texts, hf)\n",
        "retriever = db.as_retriever(\n",
        "                            search_type=\"similarity\",\n",
        "                            search_kwargs={'k': 3}\n",
        "                        )"
      ],
      "metadata": {
        "id": "qnQ00eoy1Oy2"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | llm_chain\n",
        ")\n"
      ],
      "metadata": {
        "id": "MAzZ98vb6iKO"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "hmwgKdTDAfdF"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = rag_chain.invoke(\"이스트소프트의 핵심가치는?\")\n",
        "\n",
        "for i in result['context']:\n",
        "    print(f\"주어진 근거: {i.page_content} / 출처: {i.metadata['source']} - {i.metadata['page']} \\n\\n\")\n",
        "\n",
        "print(f\"\\n답변: {result['text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tRBrNeE_8x1",
        "outputId": "233de7b3-849b-492f-ac63-063f840ecf43"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "주어진 근거: 임직원(명)\n",
            "173\n",
            "이스트소프트는 차별화된 인공지능 기술을  \n",
            "주축으로 크게 \n",
            "AI HUMAN,  COMMERCE,  TECHFIN,  \n",
            "SECURITY , GAME 5가지 사업을 추진하\n",
            "고 있습니다.\n",
            "각 분야에 기술적 혁신을 창출하여 AI를 통\n",
            "한 PLUS된 서비스 경험을 만들어 내고 있\n",
            "습니다.\n",
            "핵심가치\n",
            "잘하는 일을 합니다.\n",
            "우리는 각자 자기 자신이 무엇을 잘 하는지 알고 있습니다.  내가 잘하는 일을 하여 성과를 내고 보람을 느낍니다.\n",
            "부끄럽지 않은 일을 합니다.\n",
            "빠른 길이 바른 길이 아니라면 가지 않습니다.  선을 지키는 올바른 길을 선택합니다.\n",
            "익숙함에 익숙해지지 않습니다.\n",
            "관성을 경계합니다.   낯선 것을 받아들이며 배우고 발전시키는 도전을 즐깁니다. / 출처: /content/drive/MyDrive/Colab Notebooks/ESTsoft - The most universal interface for human.pdf - 1 \n",
            "\n",
            "\n",
            "주어진 근거: AI 기술을  바탕으로  한  최고의  서비스  기업\n",
            "이스트소프트  입니다 .\n",
            "Reimagining y our e veryday life wit h AI Human\n",
            "AI Human Lab 회사소개 사업소개 연혁 윤리경영 공지사항\n",
            "보다 편리하고 , 안전한  세상을  위한  \n",
            "실용주의 ( 實用主義\u0000\u0000인공지 능 \u0000\n",
            "바로 \u0000\u0000이스 트소프트 가 \u0000 지 향 하 는 \u0000 가 치입니 다 \u0000\n",
            "우리가 제공하는 실용주의 인공지능은 서비스나 제품으로 사용화하는데 오랜 시간이 걸리는 미래의 것이 아닙니다.  \n",
            "지금 바로 우리의 일상에 인공지능 기술을 더해 업무와 생활에 편의를 높일 수 있는 기술 즉,  'AI PLUS'입니다.  \n",
            "더 편리한 우리의 일상,  더 안전한 세상을 만들기 위해 노력하는 것,  이것이 바로 이스트소프트가 만들어 가는 실용주의 인공지능입니\n",
            "다. \n",
            "이스트소프트는 고도화된 인공지능으로 더욱 안전하고 편리한 세상을 만들어 나가겠습니다.\n",
            "설립일\n",
            "1993. 10. 02\n",
            "자본금(원)\n",
            "55.8억 / 출처: /content/drive/MyDrive/Colab Notebooks/ESTsoft - The most universal interface for human.pdf - 0 \n",
            "\n",
            "\n",
            "주어진 근거: 5.Software with AI\n",
            "알캡처 등에 적용된 배경제거  \n",
            "기술과같이 기술과 운로드\n",
            " 03214  통신판매업신고번호 2011-서울서초-1962\n",
            " 이스트빌딩(우)06711\n",
            " 방침Connect / 출처: /content/drive/MyDrive/Colab Notebooks/ESTsoft - The most universal interface for human.pdf - 4 \n",
            "\n",
            "\n",
            "\n",
            "답변: \n",
            "### [INST]\n",
            "Instruction: Answer the question based on your knowledge.\n",
            "Here is context to help:\n",
            "\n",
            "[Document(page_content='임직원(명)\\n173\\n이스트소프트는 차별화된 인공지능 기술을  \\n주축으로 크게 \\nAI HUMAN,  COMMERCE,  TECHFIN,  \\nSECURITY , GAME 5가지 사업을 추진하\\n고 있습니다.\\n각 분야에 기술적 혁신을 창출하여 AI를 통\\n한 PLUS된 서비스 경험을 만들어 내고 있\\n습니다.\\n핵심가치\\n잘하는 일을 합니다.\\n우리는 각자 자기 자신이 무엇을 잘 하는지 알고 있습니다.  내가 잘하는 일을 하여 성과를 내고 보람을 느낍니다.\\n부끄럽지 않은 일을 합니다.\\n빠른 길이 바른 길이 아니라면 가지 않습니다.  선을 지키는 올바른 길을 선택합니다.\\n익숙함에 익숙해지지 않습니다.\\n관성을 경계합니다.   낯선 것을 받아들이며 배우고 발전시키는 도전을 즐깁니다.', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/ESTsoft - The most universal interface for human.pdf', 'page': 1}), Document(page_content=\"AI 기술을  바탕으로  한  최고의  서비스  기업\\n이스트소프트  입니다 .\\nReimagining y our e veryday life wit h AI Human\\nAI Human Lab 회사소개 사업소개 연혁 윤리경영 공지사항\\n보다 편리하고 , 안전한  세상을  위한  \\n실용주의 ( 實用主義\\x00\\x00인공지 능 \\x00\\n바로 \\x00\\x00이스 트소프트 가 \\x00 지 향 하 는 \\x00 가 치입니 다 \\x00\\n우리가 제공하는 실용주의 인공지능은 서비스나 제품으로 사용화하는데 오랜 시간이 걸리는 미래의 것이 아닙니다.  \\n지금 바로 우리의 일상에 인공지능 기술을 더해 업무와 생활에 편의를 높일 수 있는 기술 즉,  'AI PLUS'입니다.  \\n더 편리한 우리의 일상,  더 안전한 세상을 만들기 위해 노력하는 것,  이것이 바로 이스트소프트가 만들어 가는 실용주의 인공지능입니\\n다. \\n이스트소프트는 고도화된 인공지능으로 더욱 안전하고 편리한 세상을 만들어 나가겠습니다.\\n설립일\\n1993. 10. 02\\n자본금(원)\\n55.8억\", metadata={'source': '/content/drive/MyDrive/Colab Notebooks/ESTsoft - The most universal interface for human.pdf', 'page': 0}), Document(page_content='5.Software with AI\\n알캡처 등에 적용된 배경제거  \\n기술과같이 기술과 운로드\\n 03214  통신판매업신고번호 2011-서울서초-1962\\n 이스트빌딩(우)06711\\n 방침Connect', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/ESTsoft - The most universal interface for human.pdf', 'page': 4})]\n",
            "\n",
            "### QUESTION:\n",
            "이스트소프트의 핵심가치는?\n",
            "\n",
            "[/INST]\n",
            " 1. 잘 하는 일을 합니다.\n",
            " 2. 부끄럽지 않은 일을 합니다.\n",
            " 3. 빠른 길이 바른 길이 아니라면 가지 않습니다.\n",
            " 4. 익숙함에 익숙해지지 않습니다.\n",
            " 5. 관성을 경계합니다.\n",
            " 6. 낯선 것을 받아들이며 배우고 발전시키는 도전을 즐깁니다.\n",
            "\n",
            "정답은 1. 잘 하는 일을 합니다.\n"
          ]
        }
      ]
    }
  ]
}